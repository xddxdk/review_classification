{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d50d57e",
   "metadata": {},
   "source": [
    "**3. Neuron Model**\n",
    "\n",
    "Evaluation and Training RuBERT model for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2e95fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d76a5c9",
   "metadata": {},
   "source": [
    "- Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37903645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean function\n",
    "RE_HTML = re.compile(r'<.*?>')\n",
    "RE_EMOJI = re.compile(r'[\\U00010000-\\U0001FFFF]', flags=re.UNICODE)\n",
    "\n",
    "def clean_for_transf(text):\n",
    "    text = RE_HTML.sub('', text) # HTML\n",
    "    text = RE_EMOJI.sub('', text) # Emoji\n",
    "    text = re.sub(r\"[^а-яА-Яa-zA-Z0-9\\s.,!?\\\"'()\\-–—]\", ' ', text) # extra special characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # extra spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883249bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Data prepare\n",
    "df = pd.read_csv(\"data/data.csv\")\n",
    "print(df['text'].isnull().sum())\n",
    "df = df.dropna(subset=['text'])\n",
    "print(df['text'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b961970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Clean\n",
    "df['clean_text']=df['text'].astype(str).apply(clean_for_transf)\n",
    "#df.to_csv(\"clean_transf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "610b5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Split\n",
    "X = df['clean_text']\n",
    "y = df['relevant']\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X.tolist(), y.tolist(), test_size=0.2, random_state=42, stratify=y, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp, shuffle=True)\n",
    "\n",
    "# Index drop (for training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984aafa",
   "metadata": {},
   "source": [
    "- Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "792f18f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cointegrated/rubert-tiny2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8989dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class for ruBert model\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.encodings = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length\n",
    "        )\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(self.encodings[\"input_ids\"][idx]),\n",
    "            \"attention_mask\": torch.tensor(self.encodings[\"attention_mask\"][idx]),\n",
    "            \"label\": torch.tensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a48e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ReviewDataset(X_train, y_train, tokenizer)\n",
    "test_dataset = ReviewDataset(X_test, y_test, tokenizer)\n",
    "val_dataset = ReviewDataset(X_val, y_val, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aff5f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainings parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./rubert_results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=300,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    use_cpu=True,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df175b6",
   "metadata": {},
   "source": [
    "- Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8ec7ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"f1\": f1_score(labels, preds),\n",
    "        \"precision\": precision_score(labels, preds),\n",
    "        \"recall\": recall_score(labels, preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "471b024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1634' max='1634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1634/1634 20:04, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.461800</td>\n",
       "      <td>0.443239</td>\n",
       "      <td>0.853071</td>\n",
       "      <td>0.812809</td>\n",
       "      <td>0.897530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.443949</td>\n",
       "      <td>0.855091</td>\n",
       "      <td>0.833232</td>\n",
       "      <td>0.878127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1634, training_loss=0.45374708339079506, metrics={'train_runtime': 1205.0232, 'train_samples_per_second': 43.36, 'train_steps_per_second': 1.356, 'total_flos': 96325578624000.0, 'train_loss': 0.45374708339079506, 'epoch': 2.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, use_safetensors=True)\n",
    "model.to(device)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=val_dataset, compute_metrics=compute_metrics)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c9b4ad",
   "metadata": {},
   "source": [
    "- Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4524df00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.59      2473\n",
      "           1       0.83      0.87      0.85      6236\n",
      "\n",
      "    accuracy                           0.78      8709\n",
      "   macro avg       0.73      0.71      0.72      8709\n",
      "weighted avg       0.78      0.78      0.78      8709\n",
      "\n",
      "F1: 0.852561595619867\n",
      "Precision: 0.8321881203237136\n",
      "Recall: 0.8739576651699807\n",
      "ROC AUC: 0.8403\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "y_true = predictions.label_ids\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_scores = predictions.predictions[:, 1]\n",
    "roc_auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(\"F1:\", f1_score(y_true, y_pred))\n",
    "print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "print(f'ROC AUC: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525565ca",
   "metadata": {},
   "source": [
    "RuBERT model has more comlex architecture, so this model predict more accurately then classic ML models.\n",
    "\n",
    "It has better precision, f1 and roc auc.\n",
    "\n",
    "The model takes longer to train, but it gives better metrics.\n",
    "\n",
    "So, this is the best choice for this task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
