# ReadMe для проекта "Классификация отзывов"

## Описание проекта
Проект "Классифиакция отзывов" направлен на построение модели, способной успешно классифицировать отзывы на релевантные и нерелевантные, для обеспечения более качественного анализа мнений людей о ВУЗах России. В рамках проекта были выполнены следующие этапы:
- Загрузка и обработка текста из набора данных с отзывами.
  - Работа с регулярными выражениями, удаление стоп-слов, лемматизация для Classic ML моделей.
  - Удаление эмодзи, минимальная очистка лишних спецсимволов, отсутствие лемматизации и очистки стоп-слов для предобученной модели.
- Разделение данных на обучающую, валидационную и тестовую выборки.
- Построение классических ML моделей и побор параметров с помощью Optuna.
- Построение предобученной модели на основе cointegrated/rubert-tiny2 из Hugging Face с последующим fine-tuning'ом модели.
- Оценка моделей с использованием метрик: F1, Recall, Precision, ROC-AUC.
- Сохранение финальной модели и лучших гиперпараметров.

## Используемые технологии и библиотеки

- **Машинное обучение**: Scikit-Learn, PyTorch, CatBoost, transformers
- **Подбор параметров**: Optuna
- **Работа с данными**: NumPy, Pandas, re, nltk, spacy
- **Язык программирования**: Python
- **Инструменты**: Jupyter Notebook

## Данные
Датасет представляет из себя 43 000 размеченных отзывов людей о ВУЗах, на основе релевантности, то есть наличия реального мнения о каком-либо ВУЗе, отсутствие спама, рекламы и т.д. Столбцы: text, relevant. text - это текст отзыва, relevant - принимает значения 1 или 0, где 1 - релевантный отзыв, 0 - не релевантный.

## Классические модели (classic_models.ipynb)
Задача сводится к бинарной классификации. Используем классические методы классификации текстов. Использовались: Logistic Regression, Random Forest, Catboost. Параметры моделей были оптимизированы с помощью Optuna. Данные предварительно очищены (стоп-слова, html, emoji, лемматизация) и токенизированы. 

Лучшая модель - Logisitc Regression: F1 = 0.848, precision = 0.766, recall = 0.949, ROC AUC = 0.794.

## Предобученные нейросети (transformers.ipynb)
Стандартный и эффективный подход при решении подобных задач - использование предобученных нейросетей. В нашем случае модель из Hugging Face на основе Bert - cointegrated/rubert-tiny2. Проведена собственная подготовка данных (без лемматизации и удаления стоп слов, убирали минимум ненужных спецсимволов). В ходе работы был сделан fine-tuning модели, модель обучилась достаточно быстро. 

Лучший результат: F1 = 0.852, precision = 0.832, recall = 0.873, ROC AUC = 0.840.

## Итог
Лучшей моделью оказалась предобученная модель на основе cointegrated/rubert-tiny2. Ее recall выше precision (при этом precision заметно больше чем у классических моделей), что отлично подходит для нашей задачи фильтрации релевантных текстов, которые в дальнейшем также будут обработаны и изучены. Также модель обладает наибольшим F1 и сильно превосходит классические модели по ROC AUC, что свидетельствует о лучшем "понимании" где на самом деле релевантные отзывы, а где нет.

## Структура проекта

```bash
.
├── data_preparation.ipynb   # Подготовка данных
├── classic_model.ipynb      # Классические модели
├── transformers.ipynb       # Предобученная модель
├── .gitignore               # gitignore
├── README.md                # Описание проекта
├── requirements.txt         # requirements
